---
title: "4.4 A Closer Look at Testing and <br> 4.5 Making Connections"
author: "E. Nordmoe"
date: "Math 260"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
```


```{r, echo=F,message=FALSE}
library(mosaic)
library(Lock5Data)
```


class: middle, center,inverse

# Section 4.4 A Closer Look at Testing

---


# Type I and Type II Errors

|                |       Reject $H_0$      |   Do not reject $H_0$   |
|----------------|:-----------------------:|:-----------------------:|
| $H_0$ is true  | Type I Error $(\alpha)$ |         No error        |
| $H_0$ is false |         No error        | Type II Error $(\beta)$ |

--

### Type I Error $==>$ False positive   

--
   
### Type II Error $==>$ False negative


---

# Significance Level  

The significance level, $\alpha$, represents the tolerable probability of making a Type I error.  

---

# Multiple Testing

*  When multiple hypothesis tests are conducted, the chance that at least one test incorrectly rejects a true null hypothesis increases with the number of tests.

*  If the null hypotheses are all true, $\alpha$ of the tests will yield statistically significant results just by random chance.

---
background-image: url(https://imgs.xkcd.com/comics/significant.png)
background-position: center
background-size: contain



---

## Publication Bias

* **Publication bias** refers to the fact that usually only the significant results get published.

* The one study that turns out significant gets published, and no one knows about all the insignificant results.

* This combined with the problem of multiple comparisons, can yield very misleading results.


---

## Replicating Results  

By attempting to *replicate* significant results with another study, this second study can either:  

* Reject $H_0$, providing further confirmation that $H_a$ is true 

OR

--

* Fail to reject $H_0$, suggesting that the first study may have yielded a Type I error.

---
  
## Practical vs Statistical Significance

* With small sample sizes, even large differences or effects may not be significant.

* With large sample sizes, even a very small difference or effect can be significant.

* A statistically significant result is not always practically significant, especially with large sample sizes.

---

class: middle, center,inverse

# Section 4.5 Making Connections

---

# Bootstrap and Randomization Distributions

 Bootstrap Distributions | Randomization Distributions  
:----------------------------:|:------------------------------:
Our best guess at the distribution of sample statistics | Our best guess at the distribution of sample statistics, if $H_0$ were true   
Centered around the observed sample statistic | Centered around the null hypothesized value  
Simulate sampling from the population by resampling from the original sample |   Simulate samples assuming $H_0$ were true  


---
class:center, middle, inverse

# Key difference  

### Randomization distribution assumes $H_0$ true, <br> while a bootstrap distribution does *not*

---

# Intervals and Tests


* If a 95% CI **contains** the parameter in $H_0$, then a two-tailed test should **not reject** $H_0$ at the 5% significance level.

* If a 95% CI **misses** the parameter in $H_0$, then a two-tailed test should **reject** $H_0$ at the 5% significance level.

---

# Intervals and Tests

A confidence interval represents the **range of plausible values** for the population parameter

* If the null hypothesized value is **not within** the CI, it is **not a plausible** value and **should be rejected.**  

* If the null hypothesized value is **within** the CI, it **is a plausible** value and **should not be rejected.**  

---

# Intervals and Tests

* **Confidence intervals** give you a range of plausible values for the parameter.

* A **significance test** describes the plausibility of one specific value of the parameter (through the $p$-value).

---


# Summary

*  If a null hypothesized value lies **inside** a 95% CI, a two-tailed test using $\alpha=.05$ would **not reject** $H_0$.  

*  If a null hypothesized value lies **outside** a 95% CI, a two-tailed test using $\alpha=.05$ would **reject** $H_0$.  

* **Statistical significance** is not at all the same as **practical significance**. 


