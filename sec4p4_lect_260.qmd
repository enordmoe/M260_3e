---
title: "4.4 A Closer Look at Testing"
author: "Math 260 Applied Statistics"
format:
  revealjs:
    chalkboard: true
    theme: [default, custom.scss]
    reveal-options:
      slideNumber: true
    html-math-method: mathjax
title-slide-attributes:
  data-background-color: "#EA6820"
from: markdown+emoji
execute:
  echo: true
  cache: true
---

```{r, echo=F,message=FALSE}
library(mosaic)
library(Lock5Data)
```

## Section 4.4 Topics

-   **Type I and Type II Errors**
    -   Understand false positives (Type I) and false negatives (Type II) in hypothesis testing.
-   **Multiple Testing & Publication Bias**
    -   Explore how running multiple tests and selective reporting can lead to misleading conclusions.
-   **Practical vs. Statistical Significance**
    -   Differentiate between statistically significant results and results that are practically meaningful.

## Type I and Type II Errors

|                |      Reject $H_0$       |   Do not reject $H_0$   |
|----------------|:-----------------------:|:-----------------------:|
| $H_0$ is true  | Type I Error $(\alpha)$ |        No error         |
| $H_0$ is false |        No error         | Type II Error $(\beta)$ |

<br>

### Type I Error $==>$ False positive

<br>

### Type II Error $==>$ False negative

## Significance Level

The significance level, $\alpha$, represents the tolerable probability of making a Type I error.

## Multiple Testing

-   When multiple hypothesis tests are conducted, the chance that **at** **least one test incorrectly rejects** a true null hypothesis increases with the number of tests.

-   If the null hypotheses are all true, a proportion $\alpha$ of the tests will yield statistically significant results **just by random chance**.

## 

![](https://imgs.xkcd.com/comics/significant.png)

## Publication Bias

-   **Publication bias** refers to the fact that usually only the significant results get published.

-   The one study that turns out significant gets published, and no one knows about all the insignificant results.

-   This combined with the problem of multiple comparisons, can yield very misleading results.

## Replicating Results

By attempting to *replicate* significant results with another study, this second study can either:

-   Reject $H_0$, providing further confirmation that $H_a$ is true

OR

-   Fail to reject $H_0$, suggesting that the first study may have yielded a Type I error.

## Practical vs Statistical Significance

-   With small sample sizes, even large differences or effects may not be significant.

-   With large sample sizes, even a very small difference or effect can be significant.

-   A statistically significant result is not always practically significant, especially with large sample sizes.
